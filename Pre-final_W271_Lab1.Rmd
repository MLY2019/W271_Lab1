---
title: "W271 Lab 1 -- Investigation of the 1989 Space Shuttle Challenger Accident"
author: "Lingyao Meng and Devin Robison"
geometry: margin=1in
output:
  pdf_document: default
  html_document:
    df_print: paged
fontsize: 11pt
---

**Part 1 (25 points)**

Conduct a thorough EDA of the data set, including univariate, bivariate and trivariate analysis. This should include both graphical and tabular analysis as taught in this course. Output-dump (that is, graphs and tables that don't come with explanations) will result in a very low, if not zero, score. Since the report has a page-limit, you will have to be selective when choosing visuals to illustrate your key points, associated with a concise explanation of the visuals. This EDA should begin with an inspection of the given dataset; examination of anomalies, missing values, potential of top and/or bottom code etc.
```{r message=FALSE}
#load the packages
library(car)
library(dplyr)
library(ggplot2)
library(gridExtra)
library(corrplot)
library(mcprofile)
library(lmtest)
library(sandwich)
```
```{r}
#load and summarize data
data <- read.csv("challenger.csv")
summary(data)
```
The initial inspection shows that there are five variables in the dataset and there is no missing value in any avariable. *O.ring* denotes the number of O-ring failures in a flight while *Number* denotes the total number of O-rings, which is a constant 6 for all flights. *O.ring* is the response variable of our interest. *Temp* denotes the ambient environment temperature at launch and is a potential explanatory variable. *Pressure* denotes the leak test pressure, which is the internal pressure inside the solid rocket motor. The increase of leak test pressure could possibly cause "blow holes" in the putty which is used to protect the O-ring, and thus lead to erosion of the O-ring. Therefore, *Pressure* is also considered a potential explanatory variable. 

Next we performed the univariate analysis for *O.ring*, *Temp* and *Pressure*.

# Univariate analysis of *O-ring*, *Temp* and *Pressure*
```{r fig.width=9,fig.height=3}
Oring.plot <- ggplot(data, aes(x = O.ring)) +
  geom_histogram(aes(y = ..density..), binwidth = 1, fill="#0072B2", colour="black") +
  ggtitle("O-ring failure") + 
  theme(plot.title = element_text(lineheight=1, face="bold"))

temp.plot <- ggplot(data, aes(x = Temp)) +
  geom_histogram(aes(y = ..density..), binwidth = 1, fill="#0072B2", colour="black") +
  ggtitle("Temperature") + 
  theme(plot.title = element_text(lineheight=1, face="bold"))

pressure.plot <- ggplot(data, aes(x = Pressure)) +
  geom_histogram(aes(y = ..density..), binwidth = 1, fill="#0072B2", colour="black") +
  ggtitle("Pressure") + 
  theme(plot.title = element_text(lineheight=1, face="bold"))

grid.arrange(Oring.plot, temp.plot, pressure.plot, ncol=3)
```
```{r fig.width=3,fig.height=3.5}
boxplot(data$Temp, main = "Temperature")
```
```{r}
outlier <- data %>% filter(Temp < 55)
outlier
```
From the histogram of *O.ring*, we can tell that about 70% of the flights had no O-ring failure, 20%  had only 1 failure and 10% had 2 failures. Visually, the distribution of *Temp* is slightly right skewed. From the data summary, we can also see that the median (70.00 F) is a bit larger than the mean (69.57 F). From the boxplot, we observed an outlier with the temperature lower than 55 F. After checking, we found that the outlier had 2 O-ring failures. According the Dalal's paper, the leak test pressure was originally 50 psi, then increased to 100 psi and finally 200 psi, in the sequence of flights launching. Based on the histogram of *Pressure*, we found that 200 psi leak test pressure was used in over 60% of the flights, 100 psi used in less than 10% and 50 psi used in less than 30% of the flights.

We initiated the explore on the correlations between three variables by plotting the correlation matrix.
```{r fig.width=4,fig.height=4}
correlations = cor(data[c('O.ring', 'Temp', 'Pressure')])
corrplot.mixed(correlations, lower='number', upper='ellipse')
```

There seems to be some negative correlation between *O.ring* and *Temp* and some positive correlation between *O.ring* and *Pressure*. No correlation was found between *Temp* and *Pressure*. Next, we performed the bivariate analysis between each pairs of variables.

# Bivariate analysis of *O.ring* vs. *Temp*
```{r fig.width=6,fig.height=4}
ggplot(data, aes(factor(O.ring), Temp)) +
  geom_boxplot(aes(fill = factor(O.ring))) + 
  geom_jitter() +
  ggtitle("Temperature by O-ring failures") + 
  theme(plot.title = element_text(lineheight=1, face="bold"))
```

We firsly grouped launch temperature by the number of O-ring failures and ploted each group using boxplot. Apparently, the flights with 0 O-ring failure were launched under higher temperature, than that for the flights with 1 or 2 failures. However, it worths to notice that the data size of flights with 1 or 2 O-ring failures is smaller than that of 0 failure flights. Especially, there are only 2 flights with 2 O-ring failures. 

# Bivariate analysis of *O.ring* vs. *Pressure*
```{r fig.width=6,fig.height=4}
ggplot(data, aes(x = factor(O.ring), fill = factor(O.ring))) +
  geom_bar() + 
  facet_wrap(~Pressure) +
  ggtitle("O-ring failures by pressure") + 
  theme(plot.title = element_text(lineheight=1, face="bold"))
```

In the bivariate analysis between O-ring failures and leak test pressure, 0, 1 and 2 O-ring failures were counted, respectively, at different levels of pressure. From the corresponding plot, we cannot tell obvious correlation between *Pressure* and *O.ring*. Further analysis is to be conducted for elucidating potential correlation. 

# Bivariate analysis of *Temp* vs. *Pressure*
```{r fig.width=6,fig.height=4}
ggplot(data, aes(factor(Pressure), Temp)) +
  geom_boxplot(aes(fill = factor(Pressure))) + 
  geom_jitter() +
  ggtitle("Temperature by Pressure") + 
  theme(plot.title = element_text(lineheight=1, face="bold"))
```

Bivariate analysis between launch temperature and pressure for leak test was also performed to check for potential dependence between the explanatory variables. The boxplot of temperature, grouped by pressure, seems to show that when 100 psi pressure was used, the launch temperature is higher than that when 50 or 200 psi was used. However, we cannot ensure that two variables are dependent solely based on this observation because there are only two data points for 100 psi. 

# Trivariate analysis
```{r fig.width=6,fig.height=4}
ggplot(data, aes(factor(O.ring), Temp)) +
  geom_boxplot(aes(fill = factor(O.ring))) + 
  facet_wrap(~Pressure) +
  ggtitle("Temperature by O-ring failures at different levels of pressure") + 
  theme(plot.title = element_text(lineheight=1, face="bold"))
```

Trivariate analysis was performed by examing launch temperature by O-ring failures at three different levels of leak test pressure. Similar correlation between *Temp* and *O-ring* was observed when the pressure of 200 psi was used. However, the plot at pressure levels of 50 or 100 psi didn't provide much useful information due to the small data size. 

**Part 2 (20 points)** 

(a) The authors use logistic regression to estimate the probability an O-ring will fail. In order to use this model, the authors needed to assume that each O-ring is independent for each launch. Discuss why this assumption is necessary and the potential problems with it. Note that a subsequent analysis helped to alleviate the authors' concerns about independence.

By using logistic regression to estimate the probability an O-ring will fail, the authors assumed the number of failed O-rings in a given launch to be a binomial variable. In other words, the response variable of the logistic regression was assumed to have the binomial distribution. One of the assumptions for a process to be modeled by binomial distribution is that the trials are independent of each other. In the O-ring case, each O-ring is a trial, so it's necessary to assume that each O-ring is independent for each launch to ensure the validity of model used.
However, this assumption is not necessarily true. For instance, the 6 primary O-rings locate at 2 rocket motors. It's possible for the O-rings locating at the same motor to have more similar probabilities to fail. Also, no information was provided regarding the production of O-rings. The devices produced from the same batch may have more similar probabilities to fail. If so, the assumption of independence doesn't hold any more and the logistic regression model used here is invalid. To check on potential violations of independence, the authors fit another model using a binary response to indicate whether there was an incident in a given launch. The second model doesn't require independence of each O-ring. In fact, the second model was quite close to the original model, which alleviated the authors' concerns about independence.  

(b) Estimate the logistic regression model using the explanatory variables in a linear form.

From the exploratory data analysis, we found some correlation between *Temp* and *O-ring* while the correlation between *Pressure* and *O-ring* was not very obvious. However, we still want to include *Pressure* as an explanatory variable for the first logistic regression model. For a given launch $i$, we denote the probability for an O-ring to fail as $\pi_i$, launch temperature as $t_i$ and leak test pressure as $p_i$. The first model has the following equation: 
$$
logit \left( \pi_i \right)  = log \left( \frac{\pi_i}{1 - \pi_i} \right) = \beta_0 + \beta_1 t_i + \beta_2 p_i
$$
This model was fit and estimated using the *glm* function:
```{r}
mod1 <- glm(O.ring/Number ~ Temp + Pressure, weights = Number,
               family = binomial (link = logit), data = data)
summary(mod1)
cbind(Estimate = coef(mod1), confint(mod1))
```
```{r}
c.temp <- -5
exp(c.temp*coef(mod1)['Temp'])
```
The coefficient of $t_i$ was estimated to be -0.0983 with the 95% confidence interval of -0.1941 to -0.0136, indicating that the decrease on the launch temperature would cause the increase on the odds for an O-ring to fail. Specifically, every 5F decrease in launch temperature would increase the odds for failure by around 63%. The coefficient of $p_i$ was estimated to be 0.0085 while 0 was included in the 95% confidence interval, indicating that leak test pressure may not be an important factor for explaining O-ring failure. 

(c) Perform LRTs to judge the importance of the explanatory variables in the model.

We performed likelihood ratio test using the *Anova* function to judge the importance of the explanatory varialbes in the first model. 

```{r}
Anova(mod1, test = "LR")
```
For the test of *Temp* with $H_0 : \beta_1 = 0$ vs. $H_\alpha : \beta_1 \neq 0$, we obtained the LRT statistic of 5.184 with a p-value of 0.0228. Using the Type I Error rate $alpha = 0.05$, we would reject the null hypothesis and claim that there is marginal evidence that *Temp* is important to be included in the model, given that *Pressure* is in the model. 
For the test of *Pressure* with $H_0 : \beta_2 = 0$ vs. $H_\alpha : \beta_2 \neq 0$, we obtained the LRT statistic of 1.541 with a p-value of 0.2145. Using the Type I Error rate $alpha = 0.05$, we could not reject the null hypothesis. Therefore, there is a lack of evidence to claim that *Pressure* is important to be included in the model, given that *Temp* is in the model. 

(d) The authors chose to remove Pressure from the model based on the LRTs. Based on your results, discuss why you think this was done. Are there any potential problems with removing this variable?

The authors fit a model using both *Temp* and *Pressure* and then fit another model using only *Temp*. By comparing the residual deviances of two models, they found that keeing only *Temp* in the model just increased the residual deviance by 1.54, which was not significant, indicating that *Pressure* may have a very weak effect. This is consistent with our LRT results in the above section. Actually the LRT statistic we computed for *Pressure* was equivalent to the difference in residual deviances computed by the authors. 
However, the apparently weak effect of *Pressure* might be due to limited data for 50 and 100 psi. Also, the interaction between *Temp* and *Pressure* was not considered by the authors. Given that high pressure can cause "blow holes" in the putty, it can make it easier for the hot gasses to escape. If so, the effect of pressure could be very significant when temperature is very low. Therefore, removing *Pressure* from the model could possibly cause serious information loss.

*Part 3 (35 points)**

Answer the following from Question 5 of Bilder and Loughin Section 2.4 Exercises (page 129-130):

Continuing Exercise 4, consider the simplified model $logit(\pi) = \beta_0 +  \beta_1 Temp$, where $\pi$ is the probability of an O-ring failure. Complete the following:

(a) Estimate the model.

```{r}
mod2 <- glm(O.ring/Number ~ Temp, weights = Number,
               family = binomial (link = logit), data = data)
summary(mod2)
cbind(Estimate = coef(mod2), confint(mod2))
```
The coefficient of *Temp* was estimated to be -0.1156 with the 95% confidence interval of (-0.2122, -0.0245), indicating that lower launch temperature would cause increased probability for an O-ring failure. The p-value is smaller than 0.05, so there is marginal evidence to claim that *Temp* is an important variable for explaining O-ring failure. 

(b) Construct two plots: (1) $\pi$ vs. Temp and (2) Expected number of failures vs. Temp. Use a temperature range of 31? to 81? on the x-axis even though the minimum temperature in the data set was 53?.

Given our model from (a), and required temperature range, we compute $\pi_{i}$ at each temperature as:
$$
\pi_{i} = \frac{e^{\beta_{0} + \beta_{1} \cdot t_{i}}}{1 + e^{\beta_{0} + \beta_{1} \cdot t_{i}}}
$$
Next, we use our assumption of independence of O-ring failures to compute the expected number of failures at a given temperature $t_{i}$ as:
$$
E[binom(n, \pi_{i})] = n \cdot \pi_{i} = 6 \cdot \pi_{i}
$$
```{r fig.width=8,fig.height=4}
results_df = data.frame(Temp=seq(from = 31, to = 81, by = 1))
params = predict(object=mod2, newdata = results_df, type = 'link', se = TRUE)
results_df['pi.hat'] = exp(params$fit) / (1 + exp(params$fit))
# Note that results_df['pi'] is the probability of failure at the corresponding temperature.
# Since we've assumed all our failures are independent, then our expected number of failures is the mean
#  of E[bin(n, p)] 
#     = n * p 
#     = 6 * results_df['pi']
results_df['expected_failures'] = 6*results_df['pi.hat']
prob.plot <- ggplot(data=results_df, aes(Temp, pi.hat)) +
  geom_point() +
  geom_line(color='blue') +
  ggtitle("Estimated probability of O-ring failure \nas a function of Temperature") +
  theme(plot.title = element_text(lineheight=1, face='bold'))
fail.plot <- ggplot(data=results_df, aes(Temp, expected_failures)) +
  geom_point() +
  geom_line(color='blue') +
  ggtitle("Expected number of O-ring failures \nas a function of Temperature") +
  theme(plot.title = element_text(lineheight=1, face='bold'))
grid.arrange(prob.plot, fail.plot, ncol=2)
```

(c) Include the 95% Wald confidence interval bands for $\pi$ on the plot. Why are the bands much wider for lower temperatures than for higher temperatures?

We build the 95% Wald confidence interval bounds, using the fact that our confidence interval for $logit(\pi_{i})$ as:
$$
\alpha = 0.05 \\
\hat{\beta_{0}} + \hat{\beta_{1}} \cdot t_{i} \pm Z_{1-\alpha/2} \cdot \sqrt{\widehat{Var}(\hat{\beta_{0}} + \hat{\beta_{1}} \cdot t_{i})}
$$
Then constructing a confidence interval for $\pi_{i}$ as:
$$
\frac{e^{\hat{\beta_{0}} + \hat{\beta_{1}} \cdot t_{i} \pm Z_{1-\alpha/2} \cdot \sqrt{\widehat{Var}(\hat{\beta_{0}} + \hat{\beta_{1}} \cdot t_{i})}}}{1 + e^{\hat{\beta_{0}} + \hat{\beta_{1}} \cdot t_{i} \pm Z_{1-\alpha/2} \cdot \sqrt{\widehat{Var}(\hat{\beta_{0}} + \hat{\beta_{1}} \cdot t_{i})}}}
$$
Bounds for lower temperatures are significanlty wider, because we have much fewer samples at lower temperatures, and no samples below $53^{\circ} F$.

```{r fig.width=6,fig.height=4}
alpha = 0.05
CI.preds.low = params$fit + (qnorm(p=c(alpha/2)) * params$se.fit)
CI.preds.high = params$fit + (qnorm(p=c(1-alpha/2)) * params$se.fit)
results_df['CI.pi.low'] = exp(CI.preds.low) / (1 + exp(CI.preds.low))
results_df['CI.pi.high'] = exp(CI.preds.high) / (1 + exp(CI.preds.high))
colors <- c("CI.pi.low" = "green", "CI.pi.high" = "blue", "pi.hat" = "black")
ggplot(data=results_df, aes(x=Temp), group=colors,) +
  geom_line(aes(y=pi.hat, color='pi.hat')) +
  geom_line(aes(y=CI.pi.high, color='CI.pi.high'), linetype='dashed') +
  geom_line(aes(y=CI.pi.low, color='CI.pi.low'), linetype='dotdash') +
  labs(x = "Temperature", y = "Prob. Of Failure", color = "Legend") +
  scale_color_manual(values = colors) +
  ggtitle("Estimated probability of O-ring failure as a function of \nTemperature, with 95% Wald Confidence Interval") +
  theme(plot.title = element_text(lineheight=1, face='bold'))
```

(d) The temperature was 31F at launch for the Challenger in 1986. Estimate the probability of an O-ring failure using this temperature, and compute a corresponding confidence interval. Discuss what assumptions need to be made in order to apply the inference procedures.

The probability of an O-ring failure at 31F was estimated using the following equation:
$$
\pi_{i} = \frac{e^{\beta_{0} + \beta_{1} \cdot 31}}{1 + e^{\beta_{0} + \beta_{1} \cdot 31}}
$$
```{r}
# Compute probability, above.
params = predict(mod2, newdata=data.frame(Temp=31), type = 'link', se = TRUE)
pi.hat = exp(params$fit) / (1 + exp(params$fit))
pi.hat
```
Based on our model, the estimated probability of an O-ring failure at 31F is 0.8178. Next, we looked at both the Wald and LRT confidence intervals for this temperature.

```{r}
# Compute Wald CI @ Temp = 31.
alpha=0.05
logit_pred = pi.hat + qnorm(c(alpha, 1-alpha/2))*params$se.fit
CI.pi.pred = exp(logit_pred) / ( 1 + exp(logit_pred))
paste("Wald CI:")
as.numeric(CI.pi.pred)
# Compute LR @ Temp = 31
K = matrix(data = c(1, 31), nrow=1, ncol=2)
mc.ci.profile = mcprofile(object=mod2, CM=K)
mc.ci.logit = confint(object=mc.ci.profile, level=0.95)
mc.ci = exp(mc.ci.logit$confint) / (1 + exp(mc.ci.logit$confint))
paste("MC CI:")
as.numeric(mc.ci)
```
The Wald interval we got is (0.1375, 0.9817) and the LRT interval is (0.1419, 0.9905). Since the Wald interval usually has lower true coverage and the LRT interval is pretty close to the Wald interval, we decided to report the LRT inveral.
In order to apply the inference, we need to assume that the relationship between temperature and the log-odds of O-ring failure is still linear in such temperature range. 

(e) Rather than using Wald or profile LR intervals for the probability of failure, Dalal et al. (1989) use a parametric bootstrap to compute intervals. Their process was to (1) simulate a large number of data sets (n = 23 for each) from the estimated model of  Temp; (2) estimate new models for each data set, say and (3) compute  at a specific temperature of interest. The authors used the 0.05 and 0.95 observed quantiles from the  simulated distribution as their 90% confidence interval limits. Using the parametric bootstrap, compute 90% confidence intervals separately at temperatures of 31F and 72F
```{r warning=FALSE}
compute_glm = function(X, t) {
  # Get pi estimates for sample
  pi.logit.sample = exp(mod2$coefficients[1] + mod2$coefficients[2] * X)
  pi.sample = pi.logit.sample / (1 + pi.logit.sample)
  # Sample binomial for simulated errors.
  y = rbinom(n=length(X), size=6, prob=pi.sample)
  mod.sample <- glm(formula = y/data$Number ~ X, family = binomial(link = logit), weights=data$Number)
  pi.logit.star = exp(mod.sample$coefficients[1] + mod.sample$coefficients[2] * t)
  pi.hat.star = pi.logit.star / (1 + pi.logit.star)
  
  return(pi.hat.star)
}
# set seed for repeatable results
set.seed(666)
bootstrap_estimate = function(temp) {
  samples = 23
  n_samples=2000
  # Sample from the provided data
  x = sample(data$Temp, samples*n_samples, replace=TRUE)
  xmatrix = matrix(data=unlist(x), nrow=samples, ncol=n_samples)
  save.results<-apply(X = xmatrix, MARGIN = 2, FUN = compute_glm, t = temp)
  
  return(save.results)
}
results = bootstrap_estimate(temp=31)
quantile(results, probs=c(0.05, 0.95), na.rm=TRUE)
results = bootstrap_estimate(temp=72)
quantile(results, probs=c(0.05, 0.95), na.rm=TRUE)
```

Using the parametric bootstrap, at temperatures of 31F, we obtained the 90% confidence interval of (0.1182, 0.9928) and at temperatures of 72F, we obtained the 90% confidence interval of (0.0105, 0.0685). It worths of notice that despite the lower conficence level, the bootstrap interval was wider than either the Wald or LRT interval.

(f) Determine if a quadratic term is needed in the model for the temperature.

```{r}
mod3 <- glm(O.ring/Number ~ Temp + I(Temp^2), weights = Number,
               family = binomial (link = logit), data = data)
summary(mod3)
anova(mod2, mod3, test = "Chisq")
```

We fit and estimated another model with the quadratic term for the temperatured included. Based on the likelihood ratio test, the addition of the quadratic term only dereased the residual deviance by 0.4947, which is not significant (P value ~0.4818). Therefore, we concluded that the quadratic term is not needed for the model.

**Part 4 (10 points)**

With the same set of explanatory variables in your final model, estimate a linear regression model. Explain the model results; conduct model diagnostic; and assess the validity of the model assumptions.  Would you use the linear regression model or binary logistic regression in this case?  Explain why.

First, we checked whether the data satisfies the basic requirements for an OLS model. Since we are only using temperature as our explanitory variable, it will take the form of a Simple Linear Regression (SLR) model. SLR models have a set of requirements that we need to verify (see Wooldridge 2.5).

$$
y = \beta_{0} + \beta_{1} \cdot temp
$$
```{r fig.width=6,fig.height=4}
mod4 = lm(formula = O.ring/data$Number ~ Temp, data=data)
results_df['pi.hat.linear'] = predict(mod4, newdata=results_df)

ggplot(results_df, aes(Temp, pi.hat.linear)) +  geom_line(color='red') +
  geom_point(data=data, aes(Temp, O.ring/Number)) +
  geom_smooth(data=data, method='loess', aes(Temp, O.ring/Number)) + 
  xlab("Failure Probability") + ylab("Temperature") +
  ggtitle("Predicted probability of O-ring failure at a given temperature. (Linear Model)") +
  theme(plot.title = element_text(lineheight=1, face='bold'))
```

SLR1 requires that our response variable o.ring/Number, is linear as a function of temperature or at least well approximated. As can be seen from the overlay graph, this assumption is dubious given the existing data set, and even if correct is likely unduely influenced by outliers. 

SLR 2 requires our response and explanatory variables are independent and identically distributed is also not entirely obvious, as discussed in part 2 (book question 4.a). 

SLR 3 requires that all of our explanatory variables are non-identical, which is true. 

SLR 4 Assumes that the mean of our residual values is zero. Examining the 'residuals vs fitted' plot below, we can see that this is likely not an entirely reasonable assumption, with the residuals appearing to follow more of a quadratic form. Its difficult to say for certain though, as we don't not have many low temperature data points. Additionally, given that our data set is relatively small, it may not be appropriate to rely asymptotic (CLT) assumptions. As we're asked to rely on the same set of explanatory variables for this model as those for our binary logistic regression, violation of SLR 4 may be an indicator that our OLS model is not appropriate. 

SLR 5 Homoskedacity assumption: residual variance is uncorrelated with our explanatory variables. Examining our scale-location plot, we would like to see a relatively flat line if our homoskedacticity assumption holds. This does not appear to be the case, but this ends up being an indicator that we need to rely on techniques that produce robust standard errors for our model analysis.

```{r fig.width=6,fig.height=3}
residual <- ggplot(mod4, aes(.fitted, .resid)) + geom_point() +
  geom_smooth(method="loess") + geom_abline(intercept = 0, linetype="dashed", slope=0, color='red') +
  xlab("Fitted values") + ylab("Residuals") +
  ggtitle("Residuals vs. Fitted") +
  theme(plot.title = element_text(lineheight=1, face='bold'))
skedacity <- ggplot(mod4, aes(.fitted, sqrt(abs(.stdresid)))) + geom_point(na.rm=TRUE) +
    geom_smooth(method="loess", na.rm = TRUE) + xlab("Fitted Value") +
    ylab(expression(sqrt("|Standardized residuals|"))) +
    ggtitle("Scale-Location")+
    theme(plot.title = element_text(lineheight=1, face='bold'))
grid.arrange(residual, skedacity, ncol=2)
# Based on our Heteroskedacticity observations, we will want to use robust standard errors for coeficient analysis
coeftest(mod4, vcov=vcovHC)
```

Finally, while analysis does correctly indicate that Temp is significant, with a P value 0.03195 < 0.05, it is not appropriate for our use case.

For this application, it is more appropriate to choose the binary logistic regression model. As observed in our discussion, the assumption that a linear relationship for probability of failure as a function of temperature is not obvious and even if it were a valid assumption, the output of the model itself is invalid across the range of temperatures of interest. Its prediction of a 30 percent chance of failure does not align well with our logistic regression models, and the linear model begins to predict negative probabilities at $78^{\circ}$F.

**Part 5 (10 points)**

Interpret the main result of your final model in terms of both odds and probability of failure. Summarize the final result with respect to the question(s) being asked and key takeaways from the analysis.

```{r}
odds <- exp((-5)*mod2$coefficients['Temp'])
odds
```
```{r}
odds.ci <- round(exp((-5)*confint(mod2)),2)
odds.ci
```

We estimated three logistic regression models to elucidate the key factors for an O-ring failure. Based on the analysis, we selected the one that includes launch temperature as the only explanatory variable as our final model. According to the final model, the decrease in launch temperature will increase the probability of an O-ring failure. Specifically, for every 5F decrease in temperature, the odds of an O-ring failure is estimated to increase by 1.78 times. The 95% confidence LRT interval for odds ratio is (1.13, 2.89). At 31F, which was the temperature when Challenger was launched, the probability for an O-ring failure is predicted to be 82%. The 95% confidence LRT interval for the estimated probability is (14%, 99%) while the 90% confidence parametric interval is (12%, 99%). Both intervals are wide, due to fewer observations in the low temperature region. Assuming the relationship between the log-odds of an O-ring failure and launch temperature is linear, we infer that when launching at 31F, the chance for an O-ring failure is not low.   
